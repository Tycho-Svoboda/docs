---
title: 'Examples'
description: 'These examples will illustrate how to use TensorPool'
icon: 'list'
---
### Example 1
Simple tensor addition
```python
from tensorpool import TensorPool
import torch

# All tensors created within this context manager 
# will automatically be CloudTensors
with TensorPool():
   # Create a tensor
   tensor = torch.tensor([1.0, 2.0, 3.0])

   # Perform an operation
   result = tensor + tensor

   # Realize the tensor
   result.realize()

   # Print the result
   print(result)
```

### Example 2
Sequential model walkthrough
```python
from tensorpool import TensorPool
import torch

with TensorPool():
    # Creating a torch sequential model
    model = torch.nn.Sequential(
      torch.nn.Linear(100, 5),
      torch.nn.ReLU(),
      torch.nn.Linear(5, 1),
    )
    x = torch.ones(1, 100)
    criterion = torch.nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
    target = torch.zeros(1, 3)
    normal_output: CloudTensor = model(x)
    normal_loss = criterion(normal_output, target)
    normal_loss.backward()
    optimizer.step()
    optimizer.zero_grad()
    output = model(x)
    loss = criterion(output, target)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()

    # Print the loss and output
    print("loss", loss.realize())
    print("output", output.realize())
```

### Example 3
GPT 2 Query
```python
from tensorpool import TensorPool
from transformers import GPT2LMHeadModel, AutoTokenizer

with TensorPool():
    model_name = "gpt2"
    model = GPT2LMHeadModel.from_pretrained(model_name)
    tokenizer = AutoTokenizer.from_pretrained(model_name)

    # Allows a user to ask a question
    prompt = input("Enter a prompt: ")
    inputs = tokenizer(prompt, return_tensors="pt")

    output = model.generate(
        input_ids=inputs["input_ids"],
        attention_mask=inputs["attention_mask"],
        max_length=30,
    )

    print(type(output))  # CloudTensor

    # Sometimes, TensorPool will automatically call .realize() 
    # Using tokenizers like below is one of those examples
    generated_text = tokenizer.batch_decode(output)[0]
    print(generated_text)
```